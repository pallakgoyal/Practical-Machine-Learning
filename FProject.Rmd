---
title: "ML based prediction of quality of exercise"
author: "Pallak Goyal"
date: "2023-03-27"
output: html_document
---
## Introduction
The following data analysis seeks to build a prediction for the quality of exercise by a participant. The predictors are a number of measures of the exercise. The choice of prediction algorithm was motivated by the need for prediction accuracy. There was little emphasis on the need to interpret the model. The algorithm was checked by dividing the data set into training and test data. Final tests were run for a separate test data set.
## Data Loading
```{r}
## training data link
training <- read.csv("./training.csv")
testing <- read.csv("./testing.csv")
```
## Model Building
The database consisted of 19622 observations for 160 variables. However, there was very little measured information available on certain variables. Hence, as a first step the variables having less than 10% of the total measures as NA were identified.Further the variables that were not considered relevant for the purposes of prediction were also dropped from the training data set. The code for the same is given below.
```{r}
col.details <- data.frame(index=1:160,colname=colnames(training),na.values=rep(NA,160))
for (i in 1:160){
        col.details[i,3] <- sum(is.na(training[,i]))/dim(training)[1]
}
##finding columns to use in analysis
cols.use <- col.details[col.details$na.values<=0.1,1]
##view names of columns to use by na criterion
## doing this so that I can remove some other predictors by logic
col.details[col.details$na.values<=0.1,2]
##relevant to drop user name 
cols.use <- cols.use[-2]
##relevant to drop these cols 
cols.use <- cols.use[-(1:7)]
training <- training[,cols.use]
training <- training[,-c(5:13,36:41,45:53,67:75)]
```
The training data set was split into training and test set for the purpose of cross-validation.
```{r}
##splitting data set for cross-validation
library(caret)
inTrain <- createDataPartition(training$classe,p=0.7,list=FALSE)
train.raw <- training[inTrain,]
test.raw <- training[-inTrain,]
```
The Random Forest model was considered the best method. This is because it provides good fit for non-linear models and is highly accurate.The following code was written to fit the model. It optimized the parameters to reduce the run time of the model.
```{r}
library(caret)
##adjustments to improve speed of model estimation
## set up names to avoid slowness of caret() with model syntax
str(train.raw)
str(test.raw)
y <- train.raw[,52]
x <- train.raw[,-52]
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE)
modFit <- train(x,y,method="rf",trControl=fitControl)
stopCluster(cluster)
registerDoSEQ()
modFit
modFit$resample
confusionMatrix.train(modFit)
plot(modFit)
plot(modFit$finalModel)
```
The model was further cross-validated on the test set within the training database.
```{r}
pdn <- predict(modFit,newdata = test.raw[,-52])
table(pdn)
```
## Conclusion
The predicted out of sample error is low at 1% as shown above. The model provides a good fit. It is based on the need for accurate predictions. The parameters of the model were not interpreted as that is not an objective of this exercise.